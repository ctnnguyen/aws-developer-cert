# S3

1). You have a 25 GB file that you're trying to upload to S3 but you're getting errors. What is a possible solution for this?
- [ ] The file size limit on S3 is 5 GB
- [ ] Update your bucket policy to allow the larger file
- [ ] Use Multi-Part upload when uploading files larger than 5 GB
- [ ] Encrypt the file

<details><summary>Answer</summary>
<p>
  Use Multi-Part upload when uploading files larger than 5 GB
</p>
<p>
  - Multi-Part Upload is recommended as soon as the file is over 100 MB
</p>
</details>

2). You're getting errors while trying to create a new S3 bucket named dev. You're using a new AWS Account with no S3 
buckets created before. What is a possible cause for this?
- [ ] You're missing IAM permissions to create an S3 bucket
- [ ] S3 bucket names must be globally unique and dev is already taken

<details><summary>Answer</summary>
<p>
  S3 bucket names must be globally unique and dev is already taken
</p>
</details>

3). You have enabled versioning in your S3 bucket which already contains a lot of files. Which version will the 
existing files have?
- [ ] 1
- [ ] 0
- [ ] -1
- [ ] null

<details><summary>Answer</summary>
<p>
  null
</p>
</details>

4). You have updated an S3 bucket policy to allow IAM users to read/write files in the S3 bucket, but one of the users 
complain that he can't perform a `PutObject` API call. What is a possible cause for this? 
- [ ] The S3 bucket policy must be wrong
- [ ] The user is lacking permissions
- [ ] The IAM user must have an explicit DENY in the attached IAM policy
- [ ] You need to contact AWS Support to lift this limit

<details><summary>Answer</summary>
<p>
  The IAM user must have an explicit DENY in the attached IAM policy
</p>
</details>

5). You want the content of an S3 bucket to be fully available in different AWS Regions. That will help your team 
perform data analysis at the lowest latency and cost possible. What S3 feature should you use?
- [ ] Amazon CloudFront Distributions
- [ ] S3 Replication
- [ ] S3 Versioning
- [ ] S3 Static Website Hosting

<details><summary>Answer</summary>
<p>
  S3 Replication
</p>
</details>

6). You have 3 S3 buckets. One source bucket A, and two destination buckets B and C in different AWS Regions. You 
want to replicate objects from bucket A to both bucket B and C. How would you achieve this?
- [ ] Continue replication from bucket A to bucket B, then from bucket A to bucket C
- [ ] Configure replication from bucket A to bucket B, then from bucket B to bucket C
- [ ] Configure replication from bucket A to bucket C, then from bucket C to bucket B

<details><summary>Answer</summary>
<p>
  Continue replication from bucket A to bucket B, then from bucket A to bucket C
</p>
</details>

7). Which of the following is **NOT** a Glacier Deep Archive retrieval mode?
- [ ] Standard (12 hours)
- [ ] Expedited (1 - 5 minutes)
- [ ] Bulk (48 hours)

<details><summary>Answer</summary>
<p>
  Expedited (1 - 5 minutes)
</p>
</details>

8). Which of the following is **NOT** a Glacier Flexible retrieval mode?
- [ ] Expedited (1 - 5 minutes)
- [ ] Standard (3 - 5 hours)
- [ ] Bulk (5 - 12 hours)
- [ ] Instant (10 seconds)

<details><summary>Answer</summary>
<p>
  Instant (10 seconds)
</p>
</details>
